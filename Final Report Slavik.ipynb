{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'assistmodule' from '/Users/aware/Desktop/Data Mining/Data-Mining-at-Aston-University-Course/assistmodule.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='artemii-yanushevskyi', api_key='aRmQfG7U4SAlhISYVym7')\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from IPython.display import Image\n",
    "import plotly.io as pio\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "colormap = plt.cm.RdBu\n",
    "\n",
    "exporting = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import importlib\n",
    "import assistmodule\n",
    "importlib.reload(assistmodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This report demonstrates the full process of developing a data mining solution for marketing campaign dataset, including critical insights and limitation of the solution, and how it could be improved.\n",
    "\n",
    "As stated in the coursework specification for the solution, the goal of our first model is to predict, as accurately as possible, whether or not a client will subscribe to a term deposit. The goal of the second model for cost-sensitive classification is to make the total cost as small as possible. I apply multiple techniques like Feature Engineering, Parameter Tuning, and Boosting. Alongside the reasons why it should improve the prediction accuracy for equal cost classification and decrease the cost value for cost-sensitive classification.\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "\n",
    "We are given with the dataset about marketing campaigns that were based on phone calls. Each entry in the dataset corresponds to someone who has subscribed to a bank term deposit or not. Often more than one contact to the same client was required, in order to confirm if the product would (or not) be subscribed to.\n",
    "\n",
    "The tools that I will use to develop the models are WRITTEN IN *Python* programming language, equipped with popular data mining library *sci-kit-learn*, data-frame manipulation library *Pandas*, NUMERICAL COMPUTING *NumPy*, and visualisation libraries *Plotly* and *Matplotlib*.\n",
    "\n",
    "# Data Exploration\n",
    "\n",
    "The dataset was supplied as an `arrf` file. The general description for attributes and statistics are the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataset contains 36169 entries and 17 attributes.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>termDeposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age           job  marital  education default  balance housing loan  \\\n",
       "0  58.0    management  married   tertiary      no   2143.0     yes   no   \n",
       "1  44.0    technician   single  secondary      no     29.0     yes   no   \n",
       "2  33.0  entrepreneur  married  secondary      no      2.0     yes  yes   \n",
       "3  47.0   blue-collar  married    unknown      no   1506.0     yes   no   \n",
       "4  35.0    management  married   tertiary      no    231.0     yes   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
       "0  unknown  5.0   may     261.0       1.0   -1.0       0.0  unknown   \n",
       "1  unknown  5.0   may     151.0       1.0   -1.0       0.0  unknown   \n",
       "2  unknown  5.0   may      76.0       1.0   -1.0       0.0  unknown   \n",
       "3  unknown  5.0   may      92.0       1.0   -1.0       0.0  unknown   \n",
       "4  unknown  5.0   may     139.0       1.0   -1.0       0.0  unknown   \n",
       "\n",
       "  termDeposit  \n",
       "0          no  \n",
       "1          no  \n",
       "2          no  \n",
       "3          no  \n",
       "4          no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'There are 9 categorical and 8 numerical attributes.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The statistics for categorical attributes:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>termDeposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "      <td>36169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7808</td>\n",
       "      <td>21746</td>\n",
       "      <td>18594</td>\n",
       "      <td>35512</td>\n",
       "      <td>20049</td>\n",
       "      <td>30363</td>\n",
       "      <td>23416</td>\n",
       "      <td>11013</td>\n",
       "      <td>29621</td>\n",
       "      <td>31981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                job  marital  education default housing   loan   contact  \\\n",
       "count         36169    36169      36169   36169   36169  36169     36169   \n",
       "unique           12        3          4       2       2      2         3   \n",
       "top     blue-collar  married  secondary      no     yes     no  cellular   \n",
       "freq           7808    21746      18594   35512   20049  30363     23416   \n",
       "\n",
       "        month poutcome termDeposit  \n",
       "count   36169    36169       36169  \n",
       "unique     12        4           2  \n",
       "top       may  unknown          no  \n",
       "freq    11013    29621       31981  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The statistics for numerical attributes:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36169.0</td>\n",
       "      <td>36169.0</td>\n",
       "      <td>36169.0</td>\n",
       "      <td>36169.0</td>\n",
       "      <td>36169.0</td>\n",
       "      <td>36169.0</td>\n",
       "      <td>36169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.9</td>\n",
       "      <td>1352.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>256.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>39.9</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.6</td>\n",
       "      <td>3028.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>255.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>99.8</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.0</td>\n",
       "      <td>-6847.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.0</td>\n",
       "      <td>98417.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4918.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  balance      day  duration  campaign    pdays  previous\n",
       "count  36169.0  36169.0  36169.0   36169.0   36169.0  36169.0   36169.0\n",
       "mean      40.9   1352.8     15.8     256.7       2.8     39.9       0.6\n",
       "std       10.6   3028.9      8.3     255.6       3.1     99.8       2.4\n",
       "min       18.0  -6847.0      1.0       0.0       1.0     -1.0       0.0\n",
       "25%       33.0     70.0      8.0     103.0       1.0     -1.0       0.0\n",
       "50%       39.0    445.0     16.0     180.0       2.0     -1.0       0.0\n",
       "75%       48.0   1417.0     21.0     317.0       3.0     -1.0       0.0\n",
       "max       95.0  98417.0     31.0    4918.0      63.0    871.0     275.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, meta = arff.loadarff('cworkTrain.arff')\n",
    "df = pd.DataFrame(data)\n",
    "df_original = df\n",
    "\n",
    "# all categorical attributes are in binary format\n",
    "\n",
    "df = assistmodule.decode_dataframe(df)\n",
    "\n",
    "display(\n",
    "    'The dataset contains {} entries and {} attributes.'.format(*df.shape),\n",
    "    df.head(),\n",
    "    'There are 9 categorical and 8 numerical attributes.',\n",
    "    'The statistics for categorical attributes:',\n",
    "    df.select_dtypes([object]).describe(), \n",
    "    'The statistics for numerical attributes:',\n",
    "    df.select_dtypes([float, int]).describe().round(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert attribute values month to the number (i.e. 'may' to 5) so that the ordering would have *chronological* sense (unlike alphabetical). \n",
    "\n",
    "The target attribute `termDeposit` is 'no' approximately 88.4%. That means that this is the baseline accuracy for classification. Now the baseline cost is for cost-sensitive classification is the minimum of $(36169-31981) * 10 = 41880$ ('no' for all) and $31981 * 1 = 31981$ ('yes' for all). The baseline cost is $31981$ for all 'yes' classifier. Also, we should convert the target attribute to 1 if the deposit is made and 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.to_datetime(df.month, format='%b').dt.month\n",
    "df['termDeposit'] = df['termDeposit'].apply(lambda x: 0 if x == 'no' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'termDeposit', notice that the team improves as time goes by. The number of deposits per each 1000 tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(37):\n",
    "    print(sum(df['termDeposit'].values[i*1000:i*1000+1000]), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the majority of _yes_'s are at the end of the data. We may want to shuffle rows. Also, we may use this insight to create a new feature. From 34,000 row until the end the half ARE 'yes'. However, this feature will not be useful since the test dataset doesn't have the same size.\n",
    "\n",
    "The *feature attributes* are used to predict the *target attribute*. Originally the dataset has 16 feature attributes, 8 _categorical_ (including month) and 8 _numerical_. The quick check shows that there are no missing values in 36k labelled examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributes = [atr for atr, typ in dict(df.dtypes).items()]\n",
    "assistmodule.plotattributes(df, attributes, size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the histograms for each variable showed that there were no variables that were strongly predictive of the class. Some attributes have quite imbalanced distributions of its values. Our algorithms may benefit from the Feature Engineering of some attribute values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='termDeposit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-dimensional scatter plots don’t show strong class separation; this suggests that several attributes will be needed to separate the two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job some job attribute values may need to be merged into new groups. \n",
    "Some attributes may be irrelevant/redundant. The further exploration is needed to determine the significance of the attributes. The Pearson correlation shows how attributes depend on each other.\n",
    "\n",
    "In order to see how *categorical* attributes are influencing `termDeposit` we need to *one-hot-encode* them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 job\n",
      "2 marital\n",
      "3 education\n",
      "4 default\n",
      "6 housing\n",
      "7 loan\n",
      "8 contact\n",
      "15 poutcome\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>termDeposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "0  58.0           0                0                 0              0   \n",
       "1  44.0           0                0                 0              0   \n",
       "2  33.0           0                0                 1              0   \n",
       "3  47.0           0                1                 0              0   \n",
       "4  35.0           0                0                 0              0   \n",
       "\n",
       "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
       "0               1            0                  0             0            0   \n",
       "1               0            0                  0             0            0   \n",
       "2               0            0                  0             0            0   \n",
       "3               0            0                  0             0            0   \n",
       "4               1            0                  0             0            0   \n",
       "\n",
       "   ...  month  duration  campaign  pdays  previous  poutcome_failure  \\\n",
       "0  ...      5     261.0       1.0   -1.0       0.0                 0   \n",
       "1  ...      5     151.0       1.0   -1.0       0.0                 0   \n",
       "2  ...      5      76.0       1.0   -1.0       0.0                 0   \n",
       "3  ...      5      92.0       1.0   -1.0       0.0                 0   \n",
       "4  ...      5     139.0       1.0   -1.0       0.0                 0   \n",
       "\n",
       "   poutcome_other  poutcome_success  poutcome_unknown  termDeposit  \n",
       "0               0                 0                 1            0  \n",
       "1               0                 0                 1            0  \n",
       "2               0                 0                 1            0  \n",
       "3               0                 0                 1            0  \n",
       "4               0                 0                 1            0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = assistmodule.one_hot_encode_categorical(df)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "sns.heatmap(df_one_hot_ordered.astype(float).corr(),linewidths=0.1, vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "job_admin.\n",
      "job_blue-collar\n",
      "job_entrepreneur\n",
      "job_housemaid\n",
      "job_management\n",
      "job_retired\n",
      "job_self-employed\n",
      "job_services\n",
      "job_student\n",
      "job_technician\n",
      "job_unemployed\n",
      "job_unknown\n",
      "marital_divorced\n",
      "marital_married\n",
      "marital_single\n",
      "education_primary\n",
      "education_secondary\n",
      "education_tertiary\n",
      "education_unknown\n",
      "default_no\n",
      "default_yes\n",
      "balance\n",
      "housing_no\n",
      "housing_yes\n",
      "loan_no\n",
      "loan_yes\n",
      "contact_cellular\n",
      "contact_telephone\n",
      "contact_unknown\n",
      "day\n",
      "month\n",
      "duration\n",
      "campaign\n",
      "pdays\n",
      "previous\n",
      "poutcome_failure\n",
      "poutcome_other\n",
      "poutcome_success\n",
      "poutcome_unknown\n",
      "termDeposit\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df[df['termDeposit'] == 1]\n",
    "df_neg = df[df['termDeposit'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a22159d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pos['pdays'].hist(bins=100, color='green', alpha=0.3)\n",
    "#df_neg['pdays'].hist(bins=100, color='red', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a220cf940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_neg['pdays'].hist(bins=100, color='red', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "//observation: number of pdays for \n",
    "1. histograms of pdays\n",
    "2. conditional histograms on job type\n",
    "3. variable importance from decision tree\n",
    "4. run RF with one_hot for all categorical\n",
    "5. add metrics to classifier for cross validation (fscore, prec, rec) (f10 score)\n",
    "pdays, duration, age, campaighn\n",
    "\n",
    "FEATURE ENGINEERING\n",
    "1. indicator variable: if pdays near 0, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CV & evaluation methods\n",
    "Example:\n",
    "baseline_cols = []\n",
    "cv = create_cv(df, nFolds=3)\n",
    "evaluate_on_cv(clf, df[baseline_cols + all_cols], df[ecn_col], cv)\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def get_clf_res(y_true, y_pred, index):\n",
    "    # returns df with 1 row and 9 columns (metrics that we are interested in)\n",
    "    metrics_df = pd.DataFrame(\n",
    "        columns=['TN', 'FP', 'FN', 'TP', 'Prec. cong', 'Prec. uncong', 'Rec. cong', 'Rec. uncong', 'f1 cong',\n",
    "                 'f1 uncong',\n",
    "                 'Acc. all', 'Supp. cong', 'Supp. uncong'], index=[index])\n",
    "\n",
    "    # extracting metrics\n",
    "    acc_all = accuracy_score(y_true, y_pred, normalize=True)\n",
    "    prfs = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0, 1])\n",
    "    pr_uncong, pr_cong = prfs[0][0], prfs[0][1]\n",
    "    rec_uncong, rec_cong = prfs[1][0], prfs[1][1]\n",
    "    f1_uncong, f1_cong = prfs[2][0], prfs[2][1]\n",
    "    sup_uncong, sup_cong = prfs[3][0], prfs[3][1]\n",
    "\n",
    "    print(confusion_matrix(y_true, y_pred).ravel())\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # populate df\n",
    "    metrics_df.iloc[0] = [tn, fp, fn, tp, pr_cong, pr_uncong, rec_cong, rec_uncong, f1_cong, f1_uncong,\n",
    "                          acc_all, sup_cong, sup_uncong]\n",
    "\n",
    "    # round values\n",
    "    metrics_df.loc[index] = metrics_df.loc[index].apply(lambda x: round(x, 2))\n",
    "    return metrics_df\n",
    "\n",
    "def create_cv(df, nFolds=3):\n",
    "    my_cv_iterator = []\n",
    "    my_cv_iterator_masks = []\n",
    "\n",
    "    for i in range(nFolds):\n",
    "        ind = pd.Series(data=range(len(df)))\n",
    "        start = int(len(df) * i / nFolds)\n",
    "        end = int(len(df) * (i + 1) / nFolds)\n",
    "        test_mask = ind.apply(lambda x: 1 if x >=  start and x < end else 0)\n",
    "\n",
    "        test_indices = ind[test_mask > 0]\n",
    "        train_mask = 1 - test_mask\n",
    "        train_indices = ind[test_mask == 0]\n",
    "        my_cv_iterator.append((train_indices, test_indices))\n",
    "        my_cv_iterator_masks.append((train_mask, test_mask))\n",
    "\n",
    "    # (!) return tuple, \n",
    "    # for evaluate_on_cv():   you need output[1]\n",
    "    # for sklearn (cv input): you need output[0]\n",
    "    return my_cv_iterator, my_cv_iterator_masks\n",
    "\n",
    "def evaluate_on_cv(clf, X, y, cv):\n",
    "    # print & return averaged main metrics\n",
    "    train_mask = cv[1][0][0]\n",
    "    test_mask = cv[1][0][1]\n",
    "    y_true = y[test_mask == 1]\n",
    "    y_pred = clf.fit(X[train_mask == 1], y[train_mask == 1]).predict(X[test_mask == 1])\n",
    "    res = get_clf_res(y_true, y_pred, '')\n",
    "    for i in range(1, len(cv[1])):\n",
    "        train_mask, test_mask = cv[1][i]\n",
    "        y_true = y[test_mask == 1]\n",
    "        y_pred = clf.fit(X[train_mask == 1], y[train_mask == 1]).predict(X[test_mask == 1])\n",
    "        res = pd.concat([res, get_clf_res(y_true, y_pred, '')])\n",
    "    res.loc['avg'] = [res[c].mean() for c in res.columns]\n",
    "    print(res.loc['avg'])\n",
    "    return res.loc['avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle dataset\n",
    "y = df['termDeposit']\n",
    "X = df.drop('termDeposit', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10379   260   982   435]\n",
      "[10361   277   961   457]\n",
      "[10459   245   929   424]\n",
      "TN               10399.7\n",
      "FP               260.667\n",
      "FN               957.333\n",
      "TP               438.667\n",
      "Prec. cong      0.626667\n",
      "Prec. uncong    0.916667\n",
      "Rec. cong       0.313333\n",
      "Rec. uncong     0.976667\n",
      "f1 cong         0.416667\n",
      "f1 uncong       0.943333\n",
      "Acc. all             0.9\n",
      "Supp. cong          1396\n",
      "Supp. uncong     10660.3\n",
      "Name: avg, dtype: object\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_cv(clf, X, y, create_cv(df, nFolds=3))\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = skf.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Classification\n",
    "Let's apply classification models to our dataset as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: standardise numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df.select_dtypes([int, float]).drop('termDeposit', axis=1)\n",
    "df_st_numerical = pd.DataFrame(StandardScaler().fit_transform(df_numerical.values), index=df_numerical.index, columns=df_numerical.columns)\n",
    "df.update(df_st_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that the dataframe is not quite balanced, in particular, the success rate grows as number of tries increases. Thus we should shuffle the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df, random_state=42)\n",
    "df_original = shuffle(df_original, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "df_features = df.drop('termDeposit', axis=1)\n",
    "df_target = df['termDeposit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Default Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummycls = DummyClassifier('most_frequent')\n",
    "scorescv = cross_val_score(dummycls, df_features, df_target, cv=10)\n",
    "scores['Default'] = pd.Series(scorescv)\n",
    "scores[['Default']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_impurity_decrease in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "    tree = DecisionTreeClassifier(min_impurity_decrease=min_impurity_decrease)\n",
    "    scorescv = cross_val_score(tree, df_features, df_target, cv=10)\n",
    "    name = 'Tree ' + str(min_impurity_decrease)\n",
    "    scores[name] = pd.Series(scorescv)\n",
    "\n",
    "scores[[col for col in scores if col.startswith('Tree ')]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the less the `min_impurity_decrease` is, the higher accuracy. However, the std is higher, thus the classification is less reliable.\n",
    "\n",
    "Should we see the tree for some seed with `min_impurity_decrease = 0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('termDeposit', axis=1), df['termDeposit'], test_size=0.1, random_state=45)\n",
    "tree = DecisionTreeClassifier(min_impurity_decrease=0.001)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, tree.predict(X_test)))\n",
    "print(confusion_matrix(y_test, tree.predict(X_test)))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(tree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is good enough. We can assert that it is better than the default classifier. Because the default classifier mean is way smaller than desision tree mean minus $3*std$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = pd.DataFrame()\n",
    "\n",
    "for n in range(1,16):\n",
    "    knn_all_atr = KNeighborsClassifier(n_neighbors=n)\n",
    "    scores_knn_all = cross_val_score(knn_all_atr, df_features, df_target, cv=10)\n",
    "    knn_results['{}-NN'.format(n)] = pd.Series(scores_knn_all)\n",
    "\n",
    "data = []\n",
    "for col in knn_results.columns:\n",
    "    data.append(go.Box(y=knn_results[col], name=col, showlegend=False ) )\n",
    "\n",
    "data.append(go.Scatter(x=knn_results.columns, y = knn_results.mean(), mode='lines', name='mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I chose the best KNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [8, 13, 14, 15]:\n",
    "    scores['{} Nearest N'.format(n)] = knn_results['{}-NN'.format(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0, solver='sag', max_iter=10000)\n",
    "scores_logreg = cross_val_score(logreg, df_features, df_target, cv=10)\n",
    "scores['Logistic R'] = pd.Series(scores_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_randforest = pd.DataFrame()\n",
    "for n in [10, 50]:\n",
    "    randforest = RandomForestClassifier(n_estimators=n, verbose=True, n_jobs=-1)\n",
    "    scores_randforest_cvs = cross_val_score(randforest, df_features, df_target, cv=10)\n",
    "    scores_randforest['RF {} est'.format(n)] = pd.Series(scores_randforest_cvs)\n",
    "    if n in [10, 15]:\n",
    "        scores['RandomF {} trees'.format(n)] = pd.Series(scores_randforest_cvs)\n",
    "\n",
    "data = []\n",
    "for col in scores_randforest.columns:\n",
    "    data.append(go.Box(y=scores_randforest[col], name=col, showlegend=False))\n",
    "\n",
    "data.append(go.Scatter(x=scores_randforest.columns, y = scores_randforest.mean(), mode='lines', name='Mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_randforest = pd.DataFrame()\n",
    "for n in [500]:\n",
    "    randforest = RandomForestClassifier(n_estimators=n,\n",
    "                                        #max_depth=250,\n",
    "                                        max_features=12,\n",
    "                                        min_samples_leaf=3,\n",
    "                                        verbose=True, \n",
    "                                        n_jobs=-1)\n",
    "    scores_randforest_cvs = cross_val_score(randforest, df_features, df_target, cv=10)\n",
    "    scores_randforest['RF {} est'.format(n)] = pd.Series(scores_randforest_cvs)\n",
    "    if n in [10, 15]:\n",
    "        scores['RandomF {} trees'.format(n)] = pd.Series(scores_randforest_cvs)\n",
    "\n",
    "data = []\n",
    "for col in scores_randforest.columns:\n",
    "    data.append(go.Box(y=scores_randforest[col], name=col, showlegend=False))\n",
    "\n",
    "data.append(go.Scatter(x=scores_randforest.columns, y = scores_randforest.mean(), mode='lines', name='Mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_labels\n",
    "#labels\n",
    "incorrect_labels = np.and(labels, output_labels)\n",
    "incorrect_clf_data = data[inctorrect_labels == True]\n",
    "# explloratiry analysis of incorrect classified data\n",
    "# just look at the raw data\n",
    "# make some plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more trees in the forest, the better.\n",
    "\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for col in scores.columns:\n",
    "    data.append(go.Box(y=scores[col], name=col, showlegend=False))\n",
    "\n",
    "data.append(go.Scatter(x=scores.columns, y = scores.mean(), mode='lines', name='Mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Having done preliminary inspection of the features, we will be prosess the features to make them more suitable for the classification algorithms.\n",
    "\n",
    "## Job attribute\n",
    "\n",
    "There are many different attribute values. It will negatively affect our prediction. We will group them by the percentage of 'yeses'.\n",
    "\n",
    "Sorting attributes by the success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort jobs by success rate\n",
    "group_job = df_original.groupby(['job'])[['termDeposit']].mean().sort_values(['termDeposit'])\n",
    "display(group_job)\n",
    "# group into categories\n",
    "groups = []\n",
    "y = -np.inf\n",
    "for x in [0.08, 0.1, 0.12, 0.15, 0.2, 0.25, 0.29]:\n",
    "    group = group_job.index[(y < group_job.termDeposit) & (group_job.termDeposit < x)]\n",
    "    groups.append(list(group))\n",
    "    y = x\n",
    "\n",
    "print('So the groups are', groups)\n",
    "# create a column name for each group\n",
    "colnames = []\n",
    "for group in groups:\n",
    "    colname = '-'.join([c[:4] for c in group])\n",
    "    colnames.append(colname)\n",
    "    \n",
    "print(colnames)\n",
    "df_jobs = df_original[['job']].copy(deep=True)\n",
    "# create a column for each group\n",
    "for i in range(len(groups)):\n",
    "    newcol = [1 if job in groups[i] else 0 for job in df_jobs['job']]\n",
    "    df_jobs['jobnew_' + colnames[i]] = newcol\n",
    "\n",
    "# delete job\n",
    "df_jobs = df_jobs.drop('job', axis=1)\n",
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The union of the jobs in such groups is not arbitrary, I chose to group jobs that have very close success rate. Thus the future models would be trained on lager groups, it will boost accuracy for the jobs in minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([col for col in df.columns if col.startswith('job_')], axis=1)\n",
    "for col in df_jobs.columns:\n",
    "    df.insert(1, col, df_jobs[[col]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created new columns in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age\n",
    "\n",
    "Notice that after 62 yo we see that subscription rate is constant being about 50%. Also, as we can see from histogram, the number of entries with age above 60 drops significantly.\n",
    "\n",
    "So, for age that is above 66, we will set it to be equal to 67. Now the distribution of age reminds Gaussian distribution even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['age'] > 66, 'age'] = 67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day and Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.Series(df_original['month'].astype(str).values + '.' +  df_original['day'].astype(int).astype(str).values)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m.%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created the new attribute `date`. It is defined as date via `day` and `month` attributes. Pay attention at the success rate by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdate = df.groupby('date')[['termDeposit']].mean()\n",
    "trace = go.Scatter(\n",
    "    x = groupdate.index,\n",
    "    y = groupdate['termDeposit'],\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500)\n",
    "\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exploring `month` attribute, I noticed that the success percentage is inversely proportional to the percentage of entries for this month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = pd.concat([\n",
    "    df_original.groupby('month')[['termDeposit']].mean(),\n",
    "    df_original.groupby('month')[['termDeposit']].count()/len(df)\n",
    "], axis=1)\n",
    "\n",
    "groupby.columns = ['mean', 'count']\n",
    "display(groupby)\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = groupby['count'],\n",
    "    y = groupby['mean'],\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500)\n",
    "\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "# Plot and embed in ipython notebook!\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the same holds true even for the days. The more calls are done during the day, the lesser success rate becomes. It may be because the callers are focusing on the number of calls rather than persuading the audience to make term deposit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = pd.concat([\n",
    "    df.groupby('date')[['termDeposit']].mean(),\n",
    "    df.groupby('date')[['termDeposit']].count()/max(df.groupby('date')[['termDeposit']].count().values)\n",
    "], axis=1)\n",
    "groupby.columns = ['mean', 'count']\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = groupby['count'],\n",
    "    y = groupby['mean'],\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500)\n",
    "\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "# Plot and embed in ipython notebook!\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that we may want to replace the attributes `day`, `month`, and `date` by the number of calls on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??? df.groupby('date')[['date']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be really nice if we have had the year. This way we can see how success rate depends on the day of the week.\n",
    "\n",
    "We don't need to preserve `day`, `month`, and `date` attributes, since they have become redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['day', 'month', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance\n",
    "This attribute is the most confusing. From the histogram we can infer that it is quite unlikely that for 10 present the balance attribute is between -8 and 8 pounds. It is either because their actual balance is different since they may use other means to save money. As a result the balance is not a good predictor for target attribute.\n",
    "\n",
    "### Replacing\n",
    "I will try to make balance to be more stronger estimation of the wealth by replacing the value between -8 and 8 by its estimation from more stronger predictors, such as: `education`, `marital`, `default`, `housing`, `loan`, `contact`, and `poutcome`.\n",
    "\n",
    "The good predictors for balance attribute are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'] = df_original['balance']\n",
    "\n",
    "good_predictors_ind = [*range(1, 17), *range(18, 25), *range(31,35)]\n",
    "good_predictors = []\n",
    "for i in good_predictors_ind:\n",
    "    good_predictors.append(df.columns[i])\n",
    "\n",
    "print(good_predictors)\n",
    "\n",
    "df_good_predictors = df[good_predictors]\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "\n",
    "mask = (df['balance'] < 8) & (df['balance'] > -8)\n",
    "reg.fit(df_good_predictors.loc[~mask], df['balance'].loc[~mask])\n",
    "df.loc[mask, 'balance'] = reg.predict(df_good_predictors.loc[mask])\n",
    "df[['balance']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithm\n",
    "The second reason why this will be beneficial is because the distribution is lognormal, like all human generated data usually is. I will apply function $\\log$ to the attribute values to oblatin a distribution close to Gaussian.\n",
    "\n",
    "Now we can freely apply logarithm to the attribute balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1000, 1000, num=3000)\n",
    "y = np.sign(x) * np.log(1 + np.abs(x))\n",
    "              \n",
    "trace = go.Scatter(x=x, y=y, marker={'color': 'red'}, \n",
    "                    mode=\"lines\")\n",
    "                                               \n",
    "data = [trace]\n",
    "layout=go.Layout(title=\"Graph of $\\DeclareMathOperator{\\sign}{sign} \\sign(x)\\cdot\\log(1+|x|)$\", xaxis={'title':'x'}, yaxis={'title':'y'})\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df['balance']\n",
    "df['balance'] = np.sign(x) * np.log(1 + np.abs(x))\n",
    "assistmodule.plotattributes(df, ['balance'], size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may standardise `balance` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'] = (df['balance'] - df['balance'].mean())/df['balance'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration\n",
    "\n",
    "The same approach, apply $log$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_original['duration']\n",
    "df['duration'] = np.sign(x) * np.log(1 + np.abs(x))\n",
    "assistmodule.plotattributes(df, ['duration'], size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = (df['duration'] - df['duration'].mean())/df['duration'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_original['campaign']\n",
    "assistmodule.plotattributes(df_original, ['campaign'], size=0.1)\n",
    "# x = 1/(2 + np.abs(x))\n",
    "df['campaign'] = np.log(6 + x)\n",
    "assistmodule.plotattributes(df, ['campaign'], size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.groupby('campaign')[['termDeposit']].mean().head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `campaign` attribute requires no preprocessing, because it is already quite represents the success rate quite well. The success rate decreases as the campaign number increases, $\\frac{1}{x}$-dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pdays\n",
    "\n",
    "It is not quite clear what strategy to use with `pdays` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistmodule.plotattributes(df, ['pdays'], size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['pdays']\n",
    "df['pdays'] = np.sign(2 + x) * np.log(2 + np.abs(x))\n",
    "assistmodule.plotattributes(df, ['pdays'], size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each stage of the analysis, we can notice that `pdays` attribute does not constitute any significance for the target attribute. Thus it should not be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['pdays'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for numerical attributes\n",
    "\n",
    "The application of PCA for our numerical data had output the following result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is strengthtening the conclusion from Pearson correlation matrix that the .. attribute is the most predictive of the 'yes' class.\n",
    "\n",
    "When applying classification we will use first .. PCA components that explain .. of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = set(df_features.select_dtypes([int, float]).columns)\n",
    "attributes = set(df.columns)\n",
    "numerical = list(numerical & attributes)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_numerical = StandardScaler().fit_transform(df_numerical)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "principal_components = pca.fit_transform(df_numerical)\n",
    "principal_df = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2', 'PC3'])\n",
    "principal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([principal_df, df[['termDeposit']]], axis = 1)\n",
    "display(final_df.head(), final_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('PC1', fontsize = 15)\n",
    "ax.set_ylabel('PC2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indices = final_df['termDeposit'] == target\n",
    "    ax.scatter(final_df.loc[indices, 'PC1'],\n",
    "               final_df.loc[indices, 'PC2'],\n",
    "               c = color,\n",
    "               s = 1,\n",
    "               alpha=0.1)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "df = df.drop(['date'], axis=1)\n",
    "df_features = df.drop('termDeposit', axis=1)\n",
    "df_target = df['termDeposit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Default Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummycls = DummyClassifier('most_frequent')\n",
    "scorescv = cross_val_score(dummycls, df_features, df_target, cv=10)\n",
    "scores['Default'] = pd.Series(scorescv)\n",
    "scores[['Default']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_impurity_decrease in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "    tree = DecisionTreeClassifier(min_impurity_decrease=min_impurity_decrease)\n",
    "    scorescv = cross_val_score(tree, df_features, df_target, cv=10)\n",
    "    name = 'Tree ' + str(min_impurity_decrease)\n",
    "    scores[name] = pd.Series(scorescv)\n",
    "\n",
    "scores[[col for col in scores if col.startswith('Tree ')]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the less the `min_impurity_decrease` is, the higher accuracy. However, the std is higher, thus the classification is less reliable.\n",
    "\n",
    "Should we see the tree for some seed with `min_impurity_decrease = 0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('termDeposit', axis=1), df['termDeposit'], test_size=0.1, random_state=45)\n",
    "tree = DecisionTreeClassifier(min_impurity_decrease=0.001)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, tree.predict(X_test)))\n",
    "print(confusion_matrix(y_test, tree.predict(X_test)))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(tree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is good enough. We can assert that it is better than the default classifier. Because the default classifier mean is way smaller than desision tree mean minus $3*std$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = pd.DataFrame()\n",
    "\n",
    "for n in range(1,16):\n",
    "    knn_all_atr = KNeighborsClassifier(n_neighbors=n)\n",
    "    scores_knn_all = cross_val_score(knn_all_atr, df_features, df_target, cv=10)\n",
    "    knn_results['{}-NN'.format(n)] = pd.Series(scores_knn_all)\n",
    "\n",
    "data = []\n",
    "for col in knn_results.columns:\n",
    "    data.append(go.Box(y=knn_results[col], name=col, showlegend=False ) )\n",
    "\n",
    "data.append(go.Scatter(x=knn_results.columns, y = knn_results.mean(), mode='lines', name='mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I chose the best KNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [8, 13, 14, 15]:\n",
    "    scores['{} Nearest N'.format(n)] = knn_results['{}-NN'.format(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0, solver='sag', max_iter=10000)\n",
    "scores_logreg = cross_val_score(logreg, df_features, df_target, cv=10)\n",
    "scores['Logistic R'] = pd.Series(scores_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_randforest = pd.DataFrame()\n",
    "for n in range(1, 16):\n",
    "    randforest = RandomForestClassifier(n_estimators=n)\n",
    "    scores_randforest_cvs = cross_val_score(randforest, df_features, df_target, cv=10)\n",
    "    scores_randforest['RF {} est'.format(n)] = pd.Series(scores_randforest_cvs)\n",
    "    if n in [10, 15]:\n",
    "        scores['RandomF {} trees'.format(n)] = pd.Series(scores_randforest_cvs)\n",
    "\n",
    "data = []\n",
    "for col in scores_randforest.columns:\n",
    "    data.append(go.Box(y=scores_randforest[col], name=col, showlegend=False))\n",
    "\n",
    "data.append(go.Scatter(x=scores_randforest.columns, y = scores_randforest.mean(), mode='lines', name='Mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more trees in the forest, the better.\n",
    "\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for col in scores.columns:\n",
    "    data.append(go.Box(y=scores[col], name=col, showlegend=False))\n",
    "\n",
    "data.append(go.Scatter(x=scores.columns, y = scores.mean(), mode='lines', name='Mean'))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "if exporting == True:\n",
    "    static_image_bytes = pio.to_image(fig, format='png')\n",
    "    display(Image(static_image_bytes))\n",
    "else:\n",
    "    display(iplot(fig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
