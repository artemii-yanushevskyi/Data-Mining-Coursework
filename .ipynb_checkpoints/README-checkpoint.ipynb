{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining at Aston University Course\n",
    "\n",
    "KDD (Knowledge Discovery in Databases) Process\n",
    "\n",
    "1. Develop an understanding of the domain\n",
    "2. Create target data set\n",
    "3. Data cleaning and preprocessing, reduction and projection\n",
    "4. Method selection (classification, clustering, association analysis)\n",
    "5. Extract patterns, models\n",
    "6. Interpretation\n",
    "7. Consolidating knowledge\n",
    "\n",
    "Data\n",
    "\n",
    "\n",
    "Object | Attribute 1 | Atribute 2 | Atribute 3\n",
    "--- | --- | --- | ---\n",
    "Object 1 | Attribute value 1 for object 1 | Attribute value 2 for object 1 | Attribute value 3 for object 1\n",
    "Object 2 | Attribute value 1 for object 2 | Attribute value 2 for object 2 | Attribute value 3 for object 2\n",
    "Object 3 | Attribute value 1 for object 3 | Attribute value 2 for object 3 | Attribute value 3 for object 3\n",
    "Object 4 | Attribute value 1 for object 4 | Attribute value 2 for object 4 | Attribute value 3 for object 4\n",
    "\n",
    "\n",
    "Attribute: variable, field, characteristic, feature\n",
    "\n",
    "Objects: record, case, observation, entity, instance\n",
    "\n",
    "Types of attributes:\n",
    "\n",
    "* Nominal/Categorical\n",
    "    * ```{juice, beer, soda, …}```\n",
    "    * Names, Labels\n",
    "    * Eye color\n",
    "* Ordinal\n",
    "    * Energy efficiency ```{C, B, A, A+, A++}```\n",
    "    * ```{bad, average, above average, good}```\n",
    "    * ```{hot > mild > cool}```\n",
    "* Interval\n",
    "    * Temperatures\n",
    "    * Dates, times\n",
    "* Ratio\n",
    "    * Distance\n",
    "    * Real numbers\n",
    "\n",
    "\n",
    "Discrete | continuos\n",
    "--- | ---\n",
    "Countable | Infinite\n",
    "Usually Integers | Real numbers\n",
    "Zip codes, set of words, binary | Hight, weight, temperature\n",
    "\n",
    "\n",
    "# Data mining tasks\n",
    "\n",
    "Classification\n",
    "\n",
    "* Predict the class of an object based on its features\n",
    "\n",
    "Regression\n",
    "\n",
    "* Estimate the value for unknown variable based for an object on its attributes\n",
    "\n",
    "Clustering\n",
    "\n",
    "* Unite similar objects in subgroups (clusters)\n",
    "\n",
    "Association Rule Discovery\n",
    "\n",
    "* What things go together\n",
    "\n",
    "Outlier/Anomaly detection \n",
    "\n",
    "* Detect significant deviations from normal behavior\n",
    "\n",
    "# Data Exploration\n",
    "\n",
    "> Frequency(attribute value) = proportion of time the value occurs in the data set\n",
    "\n",
    "> Mode(attribute value) = most frequent attribute values\n",
    "\n",
    "\n",
    "# Percentiles \n",
    "\n",
    "An ordinal or continuous attribute $x$\n",
    "A number $p$ between 0 and 100\n",
    "\n",
    "> The $p$-th percentile is a value $x_p$ of $x$ such that $p\\%$ of the observed values of $x$ are smaller than $x_p$.\n",
    "\n",
    "> Mean(attribute) is the most common measure of the location of a sample\n",
    "\n",
    "$$mean(x) = \\bar x = \\frac1m \\sum_{i=1}^mx_i $$\n",
    "\n",
    "> Median(attribute) = value in the middle of observations, or average of 2 values in the middle\n",
    "(Trimmed mean)\n",
    "\n",
    "> Range(attribute) = difference between the largest and the smallest attribute value\n",
    "\n",
    "> Variance(attribute $x$) = $s^2_x$ = $$\\frac{\\sum(x_i - \\bar x)^2}{(m - 1)}$$\n",
    "\n",
    "> Standard deviation is a square root of the variance ($\\sqrt{s_x^2}$).\n",
    "\n",
    "\n",
    "# Visualisation Techniques\n",
    "\n",
    "## Histograms\n",
    "Distribution of attribute values\n",
    "\n",
    "How much values fall into the bin of size 10 (or 20).\n",
    "\n",
    "## Box plots\n",
    "￼\n",
    "## Scatter plots\n",
    "\n",
    "# Data quality\n",
    "Noise, Outliers, Missing values, Duplicate data\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "Sampling\n",
    "\n",
    "* Without replacement\n",
    "    * Each time item is selected it is removed\n",
    "* With replacement\n",
    "    * Non removed\n",
    "    * One object can be picked more than once\n",
    " \n",
    "\n",
    "Dimensionality reduction\n",
    "\n",
    "* Less resources needed\n",
    "* Easy visualize\n",
    "* Eliminate irrelevant features and reduce noise\n",
    "\n",
    "* Feature elimination\n",
    "* Feature extraction: PCA\n",
    "\n",
    "## PCA\n",
    "Linear combinations of the original attributes.\n",
    "Ordered in decreasing amount of variance explained.\n",
    "Orthonormal (orthogonal with unit norm), independent.\n",
    "Not easily interpretable.\n",
    "\n",
    "## Attribute transformation\n",
    "Apply a function to the attribute values\n",
    "$x^k$, $log(x)$, $sqrt(x)$\n",
    "\n",
    "## Standardisation\n",
    "Replace each original attribute by a scaled version of the attribute\n",
    "\n",
    "Scale all data in the range $[0,1]$ or $[-1,1]$\n",
    "\n",
    "$$ x'= \\frac{x - x_{\\min}}{ x_{\\max} - x_{\\min} } $$\n",
    "\n",
    "$$ x'= -1 + 2\\ \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min} } $$ \n",
    "\n",
    "## Normalisation\n",
    "Zero mean and unit variance\n",
    "\n",
    "$$x_i' = \\frac{x_i - \\bar x_i}s_{x_i}\\,,$$\n",
    "\n",
    "where\n",
    "\n",
    "$$s_{x_i} = \\frac1{(N-1)}\\sum_{\\forall k}(x_{i,k} - \\bar x_i)^2$$\n",
    "\n",
    "## Similarity and Dissimilarity\n",
    "### Euclidian distance or any other norm\n",
    "\n",
    "$$d(x,y) = ||x-y||_2 = \\sqrt{\\sum_{j=1}^M(x_j-y_j)^2}$$\n",
    "\n",
    "### Similarity for binary vectors\n",
    "\n",
    "Binary vectors\n",
    "Let $x$ and $y$ have binary attributes.\n",
    "$M_ab$ = Number of attributes where $x$ has value \n",
    "$a\\in {0,1}$ and y has value $b\\in {0,1}$\n",
    "\n",
    "### Simple Matching Coefficient\n",
    "\n",
    "$$SMC = (M_{00} + M_{11})/( M_{00} + M_{01} + M_{10} + M_{11}) $$\n",
    "\n",
    "### Jacard Similarity Coefficient\n",
    "\n",
    "$$J = M_{11} / (M_{01} + M_{10} + M_{11}) $$ \n",
    "\n",
    "### Cosine similarity\n",
    "\n",
    "$$ sim (d_1 ,d_2) = \\cos(d_1, d_2) = \\frac{d1^T \\dot d2}{norm(d_1)norm(d_2)}$$\n",
    "\n",
    "\n",
    "## Gower’s similarity index\n",
    "\n",
    "$$ sim_G(x,y) = \\frac{1}{M} \\sum sim(x_i,y_i)  $$\n",
    "\n",
    "here x, y are objects.\n",
    "\n",
    "$$ sim(x_i, y_i) = 1\\text{ if }x_i = y_i\\text{ and }0\\text{ otherwise } $$\n",
    "\n",
    "For interval/ratio\n",
    "\n",
    "$$ sim(x_i, y_i) = 1 - \\frac{|x_i - y_i|}{R_i}  $$ \n",
    "\n",
    "Where R_i is the range of i-th attribute in the data.\n",
    "\n",
    "For ordinal data: attribute a rank value to each value, then normalise and treat as interval/ratio.\n",
    "\n",
    "$$ x'_i = \\frac{rank(x_i)-1}{K-1}.$$ \n",
    "\n",
    "Dissimilarity index:\n",
    "\n",
    "$$d_G(x,y) = 1 - sim_G(x, y) $$\n",
    "\n",
    "Used for clustering.\n",
    "\n",
    "## For features\n",
    "\n",
    "### Covariance matrix \n",
    "\n",
    "$$\\sum = [[s_{11}, s_{12}], [s_{21}, s_{22}]]  $$ \n",
    "\n",
    "$$ s_{ij} = cov(x_i, x_j) = \\frac{(x_i - mean(x_i))^T \\cdot (x_j - mean(x_j))}{N-1} $$\n",
    "\n",
    "### Correlation\n",
    "\n",
    "$$\\rho _{ij} = \\frac{s_{ij}}{s_{i}*s_{j}}  $$\n",
    "\n",
    "correlation ≠ causation, look for 3rd variable.\n",
    "\n",
    "$x_i$ and $x_j$ are features.\n",
    "\n",
    "# ...\n",
    "\n",
    "In linear regression: betas are how influential are attributes\n",
    "\n",
    "$$r^2\\text{ how well model captures variation}=\\frac{\\text{variation accounted}}{\\text{total variation}} = 1 - \\frac{SS_E}{SS_T} $$\n",
    "\n",
    "$$SS_T = \\text{total spread }\\sum(y_i - mean(y)) $$\n",
    "\n",
    "Higher r^2 the better (we can trick it by not including irrelevant variables, that is why we need r_adj^2\n",
    "\n",
    "r^2 is how much (*100% percents) is explained by the model\n",
    "\n",
    "\n",
    "\n",
    "# To Learn\n",
    "\n",
    "```Keras\n",
    "Naïve Bayes\n",
    "Decision tree\n",
    "Statistics \n",
    "Labs answers, md, git\n",
    "Dim reduction , pca \n",
    "R visualisation, tutorials \n",
    "Data types\n",
    "Data similarity, types, covariant\n",
    "Covariance and dependence \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
